# GenAI_RAG  
### 01. [AI] 스프린트 미션 14

---

## 📌 미션 소개
LLM이 외부 문서의 정보를 참고하여 답변할 수 있도록 **RAG(Retrieval-Augmented Generation)** 를 구현하는 미션입니다.  
LangChain 기반으로 RAG 시스템을 구축하고, 문서와 관련된 질문을 입력하여 RAG가 적절한 답변을 생성하는지 확인합니다.

---

## 📂 사용 데이터셋
이번 미션에서는 **국세청에서 발간한 2024년 연말정산 신고 안내 문서**를 활용합니다.  
해당 문서는:

- 연말정산 절차
- 공제 항목
- 유의 사항
- 2024년 개정 세법 내용

등을 다루고 있어 RAG 실험에 적합합니다.

---

## 🧩 가이드라인

### 1️⃣ 문서 로드 및 청킹(Chunking)
- 문서를 불러오고 검색 효율을 높이기 위해 적절한 길이로 청크 분리
- 청킹 방식은 실험을 통해 최적화 (문자 길이 기반/구조 기반/의미 기반 가능)

### 2️⃣ 임베딩 생성 및 벡터 데이터베이스 구축
- 각 문서 청크에 대한 임베딩 생성
- 벡터 DB에 저장하여 검색 성능 확보
- 한국어 문서 특성에 맞는 임베딩 모델 선택 중요

### 3️⃣ 언어 모델 및 토크나이저 설정
- Hugging Face 또는 OpenAI 모델 선택
- 한국어 질의·응답 고려
- 필요한 경우 양자화(quantization)로 메모리 및 속도 최적화
- Temperature, penalty 등 LLM 생성 옵션 실험

### 4️⃣ RAG 구현
- 사용자의 질문 입력 → 관련 문서 검색 → 문서 기반 답변 생성

### 5️⃣ 다양한 질문으로 성능 평가
예시 질문:
- `연말 정산 때 비거주자가 주의할 점을 알려 줘.`
- `2024년 개정 세법 중에 월세와 관련한 내용이 있을까?`

### (선택) 🔥 고급 기법 실험
- Hybrid searching
- Multi-query retrieval
- Contextual compression
- Reranking

### (선택) 🔥 Hugging Face 외 LLM API 실험
- OpenAI / Claude 등과 비교 실험

---

## 📤 제출 안내
- **Colab Notebook 파일 제출**
- 파일명 형식: `14_{팀명}_{성함}.ipynb`

### 제출 시 포함해야 할 내용
- LangChain 기반 RAG 구현 및 응답 결과
- 마크다운 설명 (코드 의도 / 옵션 선정 이유 / 결과 분석)
- 다양한 질문 기반 성능 평가

---

## 📦 참고
- Baseline 코드 제공 (그대로 사용하지 말고 자신의 아이디어로 확장 권장)
- 국세청 연말정산 종합 안내 페이지에서 원본 데이터 다운로드 가능

---

## 🔥 RAG 프로젝트 표준 폴더 구조 (권장)