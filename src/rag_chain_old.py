import os
import yaml
import logging
from pathlib import Path
from dotenv import load_dotenv

from elasticsearch import Elasticsearch
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_elasticsearch import ElasticsearchStore


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”§ ë¡œê¹… ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
log = logging.getLogger("rag")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY ì—†ìŒ")

ES_URL = "https://localhost:9200"
ES_PASSWORD = "elastic"
ES_INDEX = "rag_chunks"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) prompts.yaml ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_prompt(name: str, version: str = None):
    base_dir = Path(__file__).resolve().parent.parent
    path = base_dir / "prompt" / "prompts.yaml"

    if not path.exists():
        raise FileNotFoundError(f"prompts.yamlì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")

    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)

    for item in data.get("prompts", []):
        if item["name"] == name and (version is None or item["version"] == version):
            return item["template"]

    raise ValueError(f"Prompt not found: {name}, version: {version}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) Embeddings & ES ì—°ê²°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log.info("ğŸ”Œ ì„ë² ë”© ëª¨ë¸ ìƒì„± ì¤‘...")
# â— match ES mapping: 1536ì°¨ì›
embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=OPENAI_API_KEY)

log.info("ğŸ”Œ Elasticsearch ì—°ê²° ì‹œë„...")
es = Elasticsearch(
    ES_URL,
    basic_auth=("elastic", ES_PASSWORD),
    verify_certs=False,
)
log.info("âœ… Elasticsearch ì—°ê²° ì„±ê³µ: %s", es.info()["version"]["number"])

# ì¸ë±ìŠ¤ ì¡´ì¬ / ë¬¸ì„œ ìˆ˜ ì ê²€
if not es.indices.exists(index=ES_INDEX):
    log.error(f"âŒ Elasticsearch ì¸ë±ìŠ¤ '{ES_INDEX}' ì—†ìŒ")
else:
    count = es.count(index=ES_INDEX)["count"]
    log.info(f"ğŸ“Œ ì¸ë±ìŠ¤ '{ES_INDEX}' ë¬¸ì„œ ìˆ˜: {count}")

vectorstore = ElasticsearchStore(
    es_connection=es,
    index_name=ES_INDEX,
    embedding=embeddings,
    vector_query_field="embedding",
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) LLM
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
llm = ChatOpenAI(model="gpt-4o-mini", api_key=OPENAI_API_KEY, temperature=0.2)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) ê²€ìƒ‰ ë° RAG ìˆ˜í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def retrieve_context(question: str, k: int = 5) -> str:
    log.info("[RETRIEVER] ê²€ìƒ‰ ì‹œì‘: '%s'", question)

    # 1) ì„ë² ë”© ë²¡í„° ì§ì ‘ ìƒì„±
    embedding_vector = embeddings.embed_query(question)
    log.info(f"ğŸ”¹ embedding length = {len(embedding_vector)}")

    # 2) LangChainì´ ì•„ë‹Œ 'ì§ì ‘' ESì— ë³´ë‚¼ KNN ì¿¼ë¦¬ ìƒì„±
    raw_knn_query = {
        "knn": {
            "field": "embedding",  # ë°˜ë“œì‹œ ES ë§¤í•‘ê³¼ ë™ì¼
            "query_vector": embedding_vector,
            "k": k,
            "num_candidates": 50,  # ì„±ëŠ¥/ì •í™•ë„ ê· í˜•
        },
        "_source": ["page_content", "source_file", "page", "section", "chunk_id"],
    }

    # 3) DevTools ì‹¤í–‰ìš©ìœ¼ë¡œ JSON ê·¸ëŒ€ë¡œ ì¶œë ¥
    log.info(
        "ğŸ“Œ [DevToolsìš© KNN Query] =================================================="
    )
    log.info(f"POST {ES_INDEX}/_knn_search\n{raw_knn_query}")
    log.info(
        "================================================================================"
    )

    # 4) Elasticsearchì— ì§ì ‘ KNN ì¿¼ë¦¬ ìˆ˜í–‰ â†’ similarity_searchì™€ ê²°ê³¼ ë¹„êµ
    try:
        es_resp = es.search(index=ES_INDEX, body=raw_knn_query)
    except Exception:
        log.error("âŒ ES ì§ì ‘ ì¡°íšŒ ì‹¤íŒ¨", exc_info=True)
        return ""

    hits = es_resp.get("hits", {}).get("hits", [])

    if not hits:
        log.warning(
            "âš  ES ì§ì ‘ KNN ê²€ìƒ‰ ê²°ê³¼ 0ê°œ â†’ vector mismatch / ë§¤í•‘ ë¶ˆì¼ì¹˜ / analyzer ë¬¸ì œ ê°€ëŠ¥"
        )
    else:
        log.info(f"ğŸ” ES ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼: {len(hits)}ê°œ (top score={hits[0]['_score']})")

    # 5) ê¸°ì¡´ ë°©ì‹ (LangChain)ë„ ì‹œë„ â†’ êµì°¨ ê²€ì¦
    try:
        docs = vectorstore.similarity_search(question, k=k)
    except Exception:
        log.error("âŒ similarity_search ì‹¤íŒ¨", exc_info=True)
        return ""

    if not docs:
        log.warning("âš  LangChain similarity_search ê²°ê³¼ 0ê°œ")
        return ""

    log.info(f"ğŸ” ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ")

    result = []
    for i, doc in enumerate(docs, start=1):
        meta = doc.metadata or {}
        log.info(
            f"[DOC {i}] chunk_id={meta.get('chunk_id')} "
            f"page={meta.get('page')} source={meta.get('source_file')}"
        )

        header = (
            f"[ë¬¸ì„œ {i}]\n"
            f"chunk_id: {meta.get('chunk_id')}\n"
            f"page: {meta.get('page')}\n"
            f"source_file: {meta.get('source_file')}\n"
            f"section: {meta.get('section')}"
        )
        result.append(f"{header}\n\n{doc.page_content}")

    return "\n\n---\n\n".join(result)


def answer_with_rag(question: str) -> str:
    context = retrieve_context(question, k=5)

    # â— contextê°€ ë¹„ì—ˆìœ¼ë©´ LLMë§Œ í˜¸ì¶œ
    if not context:
        prompt_template = load_prompt("rag_qa", "1.0.0")
        prompt = prompt_template.format(context="(ì°¸ê³  ë¬¸ì„œ ì—†ìŒ)", question=question)
        reply = llm.invoke(prompt)
        return reply.content

    # ğŸ”¥ contextì—ì„œ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œí•´ ì¶œì²˜ ëª©ë¡ ë§Œë“¤ê¸°
    sources = []
    for block in context.split("---"):
        lines = block.strip().split("\n")
        meta = {k.split(": ")[0]: k.split(": ")[1] for k in lines[:4] if ": " in k}
        if meta:
            sources.append(meta)

    prompt_template = load_prompt("rag_qa", "1.0.0")
    prompt = prompt_template.format(context=context, question=question)
    reply = llm.invoke(prompt)

    # ğŸ§¾ ì¶œì²˜ ëª©ë¡ ë¬¸ìì—´ êµ¬ì„±
    source_text = "\n".join(
        f"{i+1}) {src.get('source_file', '?')} â€” page {src.get('page', '?')} â€” chunk_id={src.get('chunk_id', '?')}"
        for i, src in enumerate(sources)
    )

    return f"""{reply.content}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ” ì°¸ê³  ë¬¸ì„œ ì¶œì²˜
{source_text}
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6) ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    question = "2024ë…„ ì—°ë§ì •ì‚°ì—ì„œ ì¤‘ì†Œê¸°ì—… ì·¨ì—…ì ì†Œë“ì„¸ ê°ë©´ê³¼ ê·¼ë¡œì†Œë“ì„¸ì•¡ê³µì œëŠ” ê°ê° ì–´ë–¤ ê¸°ì¤€ê³¼ í•œë„ì— ë”°ë¼ ì ìš©ë˜ë©°, ë‘ ê³µì œë¥¼ ë™ì‹œì— ë°›ì„ ìˆ˜ ìˆì„ ë•Œ ì‹¤ì œ ì„¸ì•¡ì— ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•´ ì¤˜."
    print("\nğŸ’¡ ì§ˆë¬¸:", question)
    print("\nğŸ“Œ RAG ê¸°ë°˜ ë‹µë³€:\n")
    print(answer_with_rag(question))
